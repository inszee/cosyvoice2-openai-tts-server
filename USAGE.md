# ä½¿ç”¨ã‚¬ã‚¤ãƒ‰ & ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ç’°å¢ƒæº–å‚™

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/ShunsukeTamura06/cosyvoice2-openai-tts-server.git
cd cosyvoice2-openai-tts-server

# Condaç’°å¢ƒä½œæˆï¼ˆæ¨å¥¨ï¼‰
conda create -n cosyvoice python=3.10
conda activate cosyvoice

# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Ÿè¡Œ
bash setup.sh
```

### 2. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•

```bash
# æ‰‹å‹•èµ·å‹•
python app.py

# ã¾ãŸã¯èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½¿ç”¨
./start_server.sh
```

### 3. å‹•ä½œç¢ºèª

```bash
# ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
python test_server.py
```

## ğŸ¯ APIä½¿ç”¨ä¾‹

### OpenAI SDKã‚’ä½¿ç”¨ã—ãŸåŸºæœ¬çš„ãªéŸ³å£°åˆæˆ

```python
from openai import OpenAI

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(
    api_key="dummy-key",  # èªè¨¼ãªã—
    base_url="http://localhost:8000/v1"
)

# æ—¥æœ¬èªéŸ³å£°åˆæˆ
response = client.audio.speech.create(
    model="cosyvoice2-0.5b",
    voice="nova",  # æ—¥æœ¬èªå¥³æ€§éŸ³å£°
    input="ã“ã‚“ã«ã¡ã¯ã€CosyVoice2ã§ã™ã€‚ä»Šæ—¥ã®å¤©æ°—ã¯ã„ã‹ãŒã§ã™ã‹ï¼Ÿ",
    response_format="mp3",
    speed=1.0
)

# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
with open("japanese_output.mp3", "wb") as f:
    f.write(response.content)

print("âœ… æ—¥æœ¬èªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ: japanese_output.mp3")
```

### å¤šè¨€èªå¯¾å¿œãƒ†ã‚¹ãƒˆ

```python
# è¤‡æ•°è¨€èªã®ãƒ†ã‚¹ãƒˆ
test_cases = [
    {"voice": "alloy", "text": "ä½ å¥½ï¼Œè¿™æ˜¯ä¸­æ–‡è¯­éŸ³åˆæˆæµ‹è¯•ã€‚", "lang": "ä¸­æ–‡"},
    {"voice": "fable", "text": "Hello, this is English TTS test.", "lang": "English"},
    {"voice": "nova", "text": "ã“ã‚“ã«ã¡ã¯ã€æ—¥æœ¬èªéŸ³å£°åˆæˆã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚", "lang": "æ—¥æœ¬èª"},
    {"voice": "shimmer", "text": "ì•ˆë…•í•˜ì„¸ìš”, í•œêµ­ì–´ ìŒì„± í•©ì„± í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.", "lang": "í•œêµ­ì–´"},
]

for i, test in enumerate(test_cases):
    response = client.audio.speech.create(
        model="cosyvoice2-0.5b",
        voice=test["voice"],
        input=test["text"],
        response_format="wav"
    )
    
    filename = f"multilang_test_{i+1}_{test['lang']}.wav"
    with open(filename, "wb") as f:
        f.write(response.content)
    
    print(f"âœ… {test['lang']}éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ: {filename}")
```

### cURLã‚’ä½¿ç”¨ã—ãŸAPIå‘¼ã³å‡ºã—

```bash
# åŸºæœ¬çš„ãªéŸ³å£°åˆæˆ
curl -X POST "http://localhost:8000/v1/audio/speech" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "cosyvoice2-0.5b",
    "input": "Hello from CosyVoice2! This is a test of the TTS system.",
    "voice": "alloy",
    "response_format": "mp3",
    "speed": 1.0
  }' \
  --output test_speech.mp3

# é€Ÿåº¦èª¿æ•´ãƒ†ã‚¹ãƒˆ
curl -X POST "http://localhost:8000/v1/audio/speech" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "cosyvoice2-0.5b",
    "input": "This is a fast speech test.",
    "voice": "echo",
    "response_format": "wav",
    "speed": 1.5
  }' \
  --output fast_speech.wav
```

## ğŸ­ éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°

### ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã®è¿½åŠ 

```python
import requests

# éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
with open("sample_voice.wav", "rb") as f:
    files = {"voice_sample": f}
    data = {
        "speaker_name": "my_custom_voice",
        "description": "ç§ã®ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«"
    }
    
    response = requests.post(
        "http://localhost:8000/v1/voice/clone",
        files=files,
        data=data
    )
    
    print(f"ã‚¯ãƒ­ãƒ¼ãƒ³çµæœ: {response.json()}")

# ã‚¯ãƒ­ãƒ¼ãƒ³ã—ãŸéŸ³å£°ã§åˆæˆ
response = client.audio.speech.create(
    model="cosyvoice2-0.5b",
    voice="my_custom_voice",  # è¿½åŠ ã—ãŸã‚«ã‚¹ã‚¿ãƒ éŸ³å£°
    input="ã‚¯ãƒ­ãƒ¼ãƒ³ã•ã‚ŒãŸéŸ³å£°ã§è©±ã—ã¦ã„ã¾ã™ã€‚",
    response_format="mp3"
)

with open("cloned_voice_output.mp3", "wb") as f:
    f.write(response.content)
```

### éŸ³å£°ä¸€è¦§ã®ç¢ºèª

```python
# åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ä¸€è¦§ã‚’å–å¾—
response = requests.get("http://localhost:8000/v1/voices")
voices = response.json()

print("åˆ©ç”¨å¯èƒ½ãªéŸ³å£°:")
for voice in voices["voices"]:
    print(f"  - {voice['id']}: {voice['name']} ({voice['type']})")
```

## ğŸ”— Difyçµ±åˆè¨­å®š

### Difyã§ã®è¨­å®šæ‰‹é †

1. **Difyç®¡ç†ç”»é¢ã«ã‚¢ã‚¯ã‚»ã‚¹**
2. **è¨­å®š â†’ ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ â†’ OpenAI-API-compatible** ã‚’é¸æŠ
3. **ä»¥ä¸‹ã®è¨­å®šã‚’å…¥åŠ›:**

```
Base URL: http://localhost:8000/v1
API Key: dummy-key
Model Type: TTS
Model Name: cosyvoice2-0.5b
```

4. **ãƒ†ã‚¹ãƒˆæ¥ç¶šå®Ÿè¡Œ**
5. **ä¿å­˜**

### Dify APIã‹ã‚‰ä½¿ç”¨

```python
import requests

# DifyçµŒç”±ã§TTSä½¿ç”¨
dify_api_key = "your-dify-api-key"
dify_endpoint = "https://api.dify.ai/v1"

response = requests.post(
    f"{dify_endpoint}/audio/speech",
    headers={
        "Authorization": f"Bearer {dify_api_key}",
        "Content-Type": "application/json"
    },
    json={
        "model": "cosyvoice2-0.5b",
        "input": "DifyçµŒç”±ã§éŸ³å£°åˆæˆã—ã¦ã„ã¾ã™ã€‚",
        "voice": "alloy"
    }
)

with open("dify_tts_output.mp3", "wb") as f:
    f.write(response.content)
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

#### 1. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

```bash
# GPU ãƒ¡ãƒ¢ãƒªãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
export CUDA_VISIBLE_DEVICES=""  # CPUå¼·åˆ¶ä½¿ç”¨
export FP16=false               # FP16ç„¡åŠ¹åŒ–

# ã¾ãŸã¯ .env ãƒ•ã‚¡ã‚¤ãƒ«ã§è¨­å®š
echo "DEVICE=cpu" >> .env
echo "FP16=false" >> .env
```

#### 2. ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—

```python
# æ‰‹å‹•ã§ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
from modelscope import snapshot_download

# CosyVoice2-0.5B
snapshot_download(
    'iic/CosyVoice2-0.5B',
    local_dir='./pretrained_models/CosyVoice2-0.5B'
)

# TTSFRDï¼ˆä¸­å›½èªå‡¦ç†ç”¨ï¼‰
snapshot_download(
    'iic/CosyVoice-ttsfrd',
    local_dir='./pretrained_models/CosyVoice-ttsfrd'
)
```

#### 3. ä¸­å›½èªéŸ³å£°ã®å•é¡Œ

```bash
# TTSFRDãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
cd pretrained_models/CosyVoice-ttsfrd/
unzip resource.zip -d .
pip install ttsfrd_dependency-0.1-py3-none-any.whl
pip install ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl
```

#### 4. ãƒãƒ¼ãƒˆè¡çª

```bash
# åˆ¥ã®ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨
export PORT=8001
python app.py

# ã¾ãŸã¯ .env ãƒ•ã‚¡ã‚¤ãƒ«ã§è¨­å®š
echo "PORT=8001" >> .env
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
import time
import statistics
from openai import OpenAI

client = OpenAI(
    api_key="dummy-key",
    base_url="http://localhost:8000/v1"
)

def benchmark_synthesis(text, iterations=5):
    """éŸ³å£°åˆæˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ"""
    times = []
    
    for i in range(iterations):
        start_time = time.time()
        
        response = client.audio.speech.create(
            model="cosyvoice2-0.5b",
            voice="alloy",
            input=text,
            response_format="wav"
        )
        
        end_time = time.time()
        synthesis_time = end_time - start_time
        times.append(synthesis_time)
        
        print(f"ãƒ†ã‚¹ãƒˆ {i+1}: {synthesis_time:.2f}ç§’")
    
    avg_time = statistics.mean(times)
    print(f"\nå¹³å‡åˆæˆæ™‚é–“: {avg_time:.2f}ç§’")
    print(f"æœ€å°æ™‚é–“: {min(times):.2f}ç§’")
    print(f"æœ€å¤§æ™‚é–“: {max(times):.2f}ç§’")

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
test_text = "This is a performance benchmark test for CosyVoice2 TTS server."
benchmark_synthesis(test_text)
```

## ğŸ³ Dockerä½¿ç”¨

### Docker Composeã§ã®èµ·å‹•

```bash
# ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•
docker-compose up -d

# ãƒ­ã‚°ç¢ºèª
docker-compose logs -f cosyvoice-tts

# ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
docker-compose down
```

### å€‹åˆ¥Dockerã‚³ãƒ³ãƒ†ãƒŠã§ã®å®Ÿè¡Œ

```bash
# ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
docker build -t cosyvoice-tts .

# ã‚³ãƒ³ãƒ†ãƒŠå®Ÿè¡Œ
docker run -d \
  --name cosyvoice-server \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/pretrained_models:/app/pretrained_models \
  -v $(pwd)/cache:/app/cache \
  cosyvoice-tts

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:8000/health
```

## ğŸ“ ãƒ­ã‚°åˆ†æ

### ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª

```bash
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ç›£è¦–
tail -f logs/cosyvoice.log

# ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ã¿è¡¨ç¤º
grep "ERROR" logs/cosyvoice.log

# åˆæˆçµ±è¨ˆã®è¡¨ç¤º
grep "synthesis" logs/cosyvoice.log | tail -10
```

## ğŸ¯ å®Ÿé‹ç”¨ã«ãŠã‘ã‚‹æ¨å¥¨è¨­å®š

### æœ¬ç•ªç’°å¢ƒç”¨è¨­å®š

```bash
# .env.production
HOST=0.0.0.0
PORT=8000
DEBUG=false
DEVICE=cuda
FP16=true
STREAMING=true
MAX_TEXT_LENGTH=500
CONCURRENT_REQUESTS=2
ENABLE_CACHING=true
LOG_LEVEL=WARNING
ENABLE_AUTH=true
API_KEY=your-secure-api-key
```

### ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·è¨­å®šï¼ˆnginxï¼‰

```nginx
server {
    listen 80;
    server_name your-tts-server.com;

    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
}
```

ã“ã‚Œã§CosyVoice2 OpenAIäº’æ›TTSã‚µãƒ¼ãƒãƒ¼ã®å®Œå…¨ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå®Œäº†ã§ã™ï¼ğŸ‰